{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongsy0113/cose461-NLP-project-choi-hong/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4m9MYGG4qE2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b2f155-7d76-4969-8687-7a6faa7d5dfe"
      },
      "source": [
        "# If you didn't install these packages, run these cells.\n",
        "# !pip install soynlp\n",
        "# !pip install konlpy\n",
        "\n",
        "from soynlp.normalizer import *\n",
        "import soynlp\n",
        "\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting soynlp\n",
            "  Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 416 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFr8oBdHAv-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fe6f4b-79fd-4540-982b-5017e38d82df"
      },
      "source": [
        "# json data 파일들을 google drive에 저장\n",
        "# google drive 에 있는 파일들을 접근하기 위해 mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3FLaHkDZG9M"
      },
      "source": [
        "# Experiment : LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIX3wWs7H9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e62420ae-bf87-4873-8d3e-045c8077490c"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/cose461/result_data_100.csv')\n",
        "df.head(10)\n",
        "# df['sents'] = df['sents'].str.replace('[', '')\n",
        "# df['sents'] = df['sents'].str.replace(']', '')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>utterance</th>\n",
              "      <th>P_gender</th>\n",
              "      <th>sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>('9fdbaeb2-3f1a-5ba2-a6a6-53d9a57fd33d', 'P02')</td>\n",
              "      <td>학교 6일에감 내일가냐? 불썅 ㅇㅎㅇㅎ ㅇㅇㅇㅇ왜안산에있어 다1교시얔ㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "      <td>['학교', '일', '일가', '?', '불썅', 'ㅇㅎㅇㅎ', 'ㅇㅇㅇ', '왜...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>('3fb66713-37a2-50e5-9b0a-afb898c06eea', 'P02')</td>\n",
              "      <td>천처니 오십셔,, 한 다섯시 맞춰서 오면 되지않으까 싶네욤 ㅎㅎ 흑흑 보고파 오뤼 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>['천', '처', '오십셔', '다섯시', '맞춰서', '오면', '되지', '않...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>('642fd586-be49-5bd9-b596-ccb2c8badab6', 'P02')</td>\n",
              "      <td>ㅋㅋㅋㅋㅋㅋㅋ 더워? 하긴여기도 그렇게안추워 ㅋㅋㅋㅋㅋㅋ벌써마지막이야?? 오늘 하루...</td>\n",
              "      <td>0</td>\n",
              "      <td>['ㅋㅋㅋ', '더워', '?', '하긴여', '기도', '그렇게', '안', '추...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>('b8d86fc3-2154-562c-b8d6-bb566d72fa4f', 'P02')</td>\n",
              "      <td>딱히읍지 나야 왜?? 인스타보니까 놀러가신거? 13일에 오는거야? 구래 볼수있늠 보...</td>\n",
              "      <td>0</td>\n",
              "      <td>['딱히', '읍', '나야', '왜', '??', '인스타', '보', '놀러',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>('ce82e17c-5730-5ed4-8bf9-40eac1f5d99a', 'P01')</td>\n",
              "      <td>속초에 월, 화 비온다고 되어있는데 화부턴 날씨가 추워지더라고 2도 내생각엔 오빠 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>['속초', '월', '화', '비', '온다고', '되어있는데', '화', '날씨...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>('c4cda8af-f443-5add-9c5d-c17859c975ae', 'P01')</td>\n",
              "      <td>근데 커피를 저기다가 흘릴일이없거든 ... ㅋㅋㅋㅋ 배고프당 너무너무너무너무 나 지...</td>\n",
              "      <td>0</td>\n",
              "      <td>['근데', '커피', '기', '다가', '흘릴', '일이', '없거든', '.....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>('a700867e-3173-5b98-b6fb-f8648d6d7fea', 'P02')</td>\n",
              "      <td>아니~ 단식원은 가본적 없어 단식원을 왜 가~ 가서 고생만 해 어차피 그런거는 다시...</td>\n",
              "      <td>0</td>\n",
              "      <td>['아니', '~', '단식', '원', '가본', '적', '없어', '단식', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>('d40c6bef-e632-5a8c-b2ac-2e910f8b3bf6', 'P02')</td>\n",
              "      <td>제관 팀플장소 차서 카퍼ㅣ드림 왔어 아이쿠,, 글게말야 ㅋㅋㅋㅋㅋㄱ 있오 나 수업 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>['제관', '팀', '플', '장소', '차서', '카퍼', 'ㅣ', '드림', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>('93ba610a-57ed-5d0e-991e-1698ebeebb51', 'P02')</td>\n",
              "      <td>주말 평일은 시간없는뎅 토욜밖에안됨 ㅇㅇ 나도 그때 제본이랑 짐정리해야됨</td>\n",
              "      <td>0</td>\n",
              "      <td>['주말', '평일', '시간', '없는', '뎅', '토욜', '안됨', 'ㅇㅇ'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>('9bd9dfd5-e432-5d15-aaff-17a3c2cdf440', 'P01')</td>\n",
              "      <td>한번 배워보고싶긴하다 오빠한테 물어봐야겠네 아~ 카페에서 커피 여유롭게 마시고싶다 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>['한번', '배워', '보고', '싶긴하다', '오빠', '물어봐야겠네', '아'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                              sents\n",
              "0           0  ...  ['학교', '일', '일가', '?', '불썅', 'ㅇㅎㅇㅎ', 'ㅇㅇㅇ', '왜...\n",
              "1           1  ...  ['천', '처', '오십셔', '다섯시', '맞춰서', '오면', '되지', '않...\n",
              "2           2  ...  ['ㅋㅋㅋ', '더워', '?', '하긴여', '기도', '그렇게', '안', '추...\n",
              "3           3  ...  ['딱히', '읍', '나야', '왜', '??', '인스타', '보', '놀러',...\n",
              "4           4  ...  ['속초', '월', '화', '비', '온다고', '되어있는데', '화', '날씨...\n",
              "5           5  ...  ['근데', '커피', '기', '다가', '흘릴', '일이', '없거든', '.....\n",
              "6           6  ...  ['아니', '~', '단식', '원', '가본', '적', '없어', '단식', ...\n",
              "7           7  ...  ['제관', '팀', '플', '장소', '차서', '카퍼', 'ㅣ', '드림', ...\n",
              "8           8  ...  ['주말', '평일', '시간', '없는', '뎅', '토욜', '안됨', 'ㅇㅇ'...\n",
              "9           9  ...  ['한번', '배워', '보고', '싶긴하다', '오빠', '물어봐야겠네', '아'...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5bj8NqZUYC1"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/cose461/data_100.csv')\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0C5o1KXCyQH"
      },
      "source": [
        "from soynlp.normalizer import *\n",
        "from konlpy.tag import Okt\n",
        "import re\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def clean(doc) :\n",
        "\n",
        "  new_doc = list()\n",
        "  doc = okt.pos(doc, norm=True)\n",
        "\n",
        "  stop_tags = ['Determiner', 'Josa', 'Foreign']\n",
        "  stop_words = ['은', '는', '이', '가', '', '이름', '계정', '주소', '신원', '전번', '금융', '번호', '소속', '기타']\n",
        "  for text, tag in doc:  \n",
        "\n",
        "    if tag in stop_tags:\n",
        "      continue\n",
        "\n",
        "    text = re.sub(r'[^ㄱ-ㅣ가-힣?.!~\\^]+', '', text)  # remove digits.  \n",
        "    text = emoticon_normalize(text, num_repeats=2) # remove repeated emoticon. e.g) ㅋㅋㅋㅋ=>ㅋㅋ, ㅠㅠㅠㅠ=>ㅠㅠ\n",
        "    text = repeat_normalize(text, num_repeats=1) # remove repeated character\n",
        "    \n",
        "    if text in stop_words or (tag=='Verb' and len(text)<=1):\n",
        "      continue\n",
        "      \n",
        "    new_doc.append(text)\n",
        "\n",
        "  return new_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzQd3_r6Sqlp"
      },
      "source": [
        "df['sents'] = df['utterance'].apply(clean)\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RsXO5MKKTWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8898a5f-7395-4cba-ab1d-ad0398d6c014"
      },
      "source": [
        "X = df['sents']\n",
        "y = df['P_gender']\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=7)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800388\n",
            "800388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3VpFun6P2SY"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgdGogzYPtHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d99a9f-b29d-48fb-df01-818d6a41d61f"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEoQZw53QUzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9e521e-8efa-4743-e3f4-7109febf3e73"
      },
      "source": [
        "threshold = 3\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)     # data 적게 할 때는 division by zero 나올수도\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 597233\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 427538\n",
            "단어 집합에서 희귀 단어의 비율: 71.58646625353924\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.374021745163459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49HpD6EbQZzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a943c82b-0a75-4e77-fd59-e26318cc9024"
      },
      "source": [
        "# 전체 단어 개수 중 빈도수 threshold 이하인 단어는 제거.\n",
        "# 0번 패딩 토큰을 고려하여 + 1\n",
        "vocab_size = total_cnt - rare_cnt + 1\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 169696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGp5qrHyQde1"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size) \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oPrFFfpQ7oJ"
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0oFQWaNoF4d"
      },
      "source": [
        "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv95-JyloHpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b40e1d-31cd-43fc-9db7-790a2638b78b"
      },
      "source": [
        "# 빈 샘플들을 제거\n",
        "X_train = np.delete(X_train, drop_train, axis=0)\n",
        "y_train = np.delete(y_train, drop_train, axis=0)\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800143\n",
            "800143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_Yq-mq8R0Jf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "cfdc55a6-eed9-4f0f-cf01-c907227c078f"
      },
      "source": [
        "print('메시지의 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('메시지의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "메시지의 최대 길이 : 1215\n",
            "메시지의 평균 길이 : 25.719396407892088\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjNMmaB2SQza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35aceec1-282e-4544-d6a1-8fe89a9e9374"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))\n",
        "\n",
        "below_threshold_len(50,X_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 50 이하인 샘플의 비율: 93.4512955809149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T0ovxUDSdfd"
      },
      "source": [
        "max_len = 50\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR0DkfIzSjEv"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import L2, L1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHQsJTg6SkcO"
      },
      "source": [
        "embedding_dim = 100\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEDC5w68bhQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c905ef0e-cfa9-4cfb-efb6-6ccb6530f7d2"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10001/10002 [============================>.] - ETA: 0s - loss: 0.5883 - acc: 0.6820\n",
            "Epoch 00001: val_acc improved from -inf to 0.69736, saving model to best_model.h5\n",
            "10002/10002 [==============================] - 209s 20ms/step - loss: 0.5883 - acc: 0.6821 - val_loss: 0.5719 - val_acc: 0.6974\n",
            "Epoch 2/15\n",
            "10000/10002 [============================>.] - ETA: 0s - loss: 0.5399 - acc: 0.7244\n",
            "Epoch 00002: val_acc improved from 0.69736 to 0.70260, saving model to best_model.h5\n",
            "10002/10002 [==============================] - 202s 20ms/step - loss: 0.5399 - acc: 0.7243 - val_loss: 0.5646 - val_acc: 0.7026\n",
            "Epoch 3/15\n",
            "10001/10002 [============================>.] - ETA: 0s - loss: 0.5002 - acc: 0.7549\n",
            "Epoch 00003: val_acc did not improve from 0.70260\n",
            "10002/10002 [==============================] - 203s 20ms/step - loss: 0.5002 - acc: 0.7549 - val_loss: 0.5676 - val_acc: 0.7018\n",
            "Epoch 4/15\n",
            "10002/10002 [==============================] - ETA: 0s - loss: 0.4639 - acc: 0.7792\n",
            "Epoch 00004: val_acc did not improve from 0.70260\n",
            "10002/10002 [==============================] - 205s 21ms/step - loss: 0.4639 - acc: 0.7792 - val_loss: 0.5820 - val_acc: 0.6976\n",
            "Epoch 00004: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdnbsig_bjiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0846af2e-5aba-40d7-d833-9dbc2e8d9973"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))\n",
        "# data_20 - 0.6718\n",
        "# data_50 - 0.7000 \n",
        "# 0.6943"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6254/6254 [==============================] - 46s 7ms/step - loss: 0.5632 - acc: 0.7040\n",
            "\n",
            " 테스트 정확도: 0.7040\n"
          ]
        }
      ]
    }
  ]
}