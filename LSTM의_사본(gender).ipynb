{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM의 사본(gender)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongsy0113/cose461-NLP-project-choi-hong/blob/main/LSTM%EC%9D%98_%EC%82%AC%EB%B3%B8(gender).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4m9MYGG4qE2",
        "outputId": "4c513901-df9e-4b60-fc52-09f782566a82"
      },
      "source": [
        "!pip install soynlp\n",
        "!pip install konlpy\n",
        "!pip install tensorflow\n",
        "\n",
        "from soynlp.normalizer import *\n",
        "import soynlp\n",
        "\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting soynlp\n",
            "  Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 416 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.0.0)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.41.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFr8oBdHAv-t",
        "outputId": "de559e76-cb71-41dc-ccef-281c4ec760ee"
      },
      "source": [
        "# json data 파일들을 google drive에 저장\n",
        "# google drive 에 있는 파일들을 접근하기 위해 mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3FLaHkDZG9M"
      },
      "source": [
        "# 1. lstm 모델\n",
        "\n",
        "https://wikidocs.net/44249 \n",
        "이 내용 거의 따라함\n",
        "\n",
        " lstm 모델 따라하기 2 의 아이디어\n",
        "- 같은 화자의 데이터는 하나의 덩어리로 처리하도록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60QRWYk6cTml"
      },
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/cose461/data_20.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EJe7zoqddkQ"
      },
      "source": [
        "## 데이터 전처리\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0C5o1KXCyQH"
      },
      "source": [
        "from soynlp.normalizer import *\n",
        "from konlpy.tag import Okt\n",
        "import re\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def clean(doc) :\n",
        "\n",
        "  doc = doc.replace('#@이모티콘#', '이모티콘')\n",
        "\n",
        "  pattern = '(#@[^#]+#)'\n",
        "  doc = re.sub(pattern, '', doc)\n",
        "\n",
        "  new_doc = list()\n",
        "  doc = okt.pos(doc, norm=True)\n",
        "\n",
        "  stop_tags = ['Determiner', 'Josa'] #, 'Foreign'] # 'foreign' 은 살려보자. ((이모티콘))으로 통일\n",
        "  stop_words = ['은', '는', '이', '가', '']\n",
        "  for text, tag in doc:  \n",
        "\n",
        "    if tag in stop_tags:\n",
        "      continue\n",
        "    \n",
        "    if tag == 'Foreign':\n",
        "      text = '((이모티콘))'\n",
        "\n",
        "    text = re.sub(r'[^ㄱ-ㅣ가-힣?.!~:())\\^]+', '', text)  # remove digits. ^, :, ) 는 들어가게\n",
        "    text = emoticon_normalize(text, num_repeats=2) # remove repeated emoticon. e.g) ㅋㅋㅋㅋ=>ㅋㅋ, ㅠㅠㅠㅠ=>ㅠㅠ\n",
        "    text = repeat_normalize(text, num_repeats=1) # remove repeated character\n",
        "    \n",
        "    if text in stop_words or (tag=='Verb' and len(text)<=1):\n",
        "      continue\n",
        "      \n",
        "    new_doc.append(text)\n",
        "\n",
        "  return new_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6AYl_ARk3Zk",
        "outputId": "e5c4baf7-4fa5-4f1e-8145-a81326236954"
      },
      "source": [
        "clean('#@시스템#사진 이름, #@이름# ♥️♥️♥️')\n",
        "#emoticon_normalize(\"ㅋㅋㅋㅋ아아아아ㅋㅋㅋ쿠ㅜㅜㅜㅜㅋㅋㅋㅋㅋ\")\n",
        "#repeat_normalize(\"아아아아아 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사진', '이름', '((이모티콘))']"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzQd3_r6Sqlp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "854dd028-3b12-4106-8eec-ccc790db332a"
      },
      "source": [
        "df['sents'] = df['utterance'].apply(clean)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>utterance</th>\n",
              "      <th>P_gender</th>\n",
              "      <th>sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>('d681fd70-af0d-5821-bd54-f411a26a2551', 'P01')</td>\n",
              "      <td>나 할미 생일이라서 파뤼파뤼~ 저녁 먹고 올게 먹구옴 나원래 혼자 먹고 방에 들어옴...</td>\n",
              "      <td>0</td>\n",
              "      <td>[나, 할미, 생일, 파뤼파뤼, ~, 저녁, 먹고, 올게, 먹구, 옴, 나, 원, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>('a9458b1e-2eb0-51b3-869e-665816baa439', 'P02')</td>\n",
              "      <td>근데 서울은 요즘 초큼 그런거같기두하공 ㅠ 부평? 삼산동? 오 상동어디??</td>\n",
              "      <td>0</td>\n",
              "      <td>[근데, 서울, 요즘, 초, 그런거, 같기두, 하, 공, ㅠ, 부평, ?, 삼산동,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>('349322b2-f378-536e-a458-334b467bbb53', 'P02')</td>\n",
              "      <td>그니까 ㅋㅋㅋㅋㅋㅋ 맘먹었어지금ㅋㅋㅋㅋㅋㅋ 담에 집들이때나 해서 같이 한번 모여보장 오올</td>\n",
              "      <td>0</td>\n",
              "      <td>[그니까, ㅋㅋㅋ, 맘, 먹었어, 지금, ㅋㅋㅋ, 담, 집들이, 때, 해서, 같이,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>('6721f5f0-5b9e-5e76-b5a8-dca6271695b0', 'P04')</td>\n",
              "      <td>내는 지하철</td>\n",
              "      <td>0</td>\n",
              "      <td>[내는, 지하철]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>('b1300897-af6a-5a39-aa15-e7901c7137c9', 'P03')</td>\n",
              "      <td>강화도?</td>\n",
              "      <td>0</td>\n",
              "      <td>[강화도, ?]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>('d869613c-5add-5b2b-8df4-7c33233ed6ee', 'P01')</td>\n",
              "      <td>여행하면서 많이 만나네 어떤 사람은 라오스에서 남친 만났대 라오스 남부를 갔대.. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[여행, 하면서, 많이, 만나네, 어떤, 사람, 라오스, 남친, 만났대, 라오스, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>('7ad5adee-b626-5d94-8a47-11e18b9fdb4d', 'P02')</td>\n",
              "      <td>둘다 똑같은데 공항은 혹시 늦거나 기다려야되거나 시간 촉박할까바 그러는거가툼 둘다똑...</td>\n",
              "      <td>0</td>\n",
              "      <td>[둘다, 똑같은데, 공항, 혹시, 늦거나, 기다려야되, 거나, 시간, 촉박할까, 바...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>('00b2ad12-cf69-5755-bdca-0f453b4f175d', 'P01')</td>\n",
              "      <td>어이없어 아니야~그냥 돌아가는것도 싫고 해서 탔어 도착지도 그냥 그 105번 내리는...</td>\n",
              "      <td>0</td>\n",
              "      <td>[어이없어, 아니야, ~, 그냥, 돌아가는것도, 싫고, 해서, 탔어, 도착, 지도,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>('74034247-a526-50d4-8494-c01e557c72cc', 'P02')</td>\n",
              "      <td>저녁에 갈거야 너는? 집에 간다고 너는? 7시 응 어디 아프니? 잘했쓰~~~ 그래라</td>\n",
              "      <td>0</td>\n",
              "      <td>[저녁, 갈거야, 너, ?, 집, 간다, 너, ?, 시, 응, 어디, 아프니, ?,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>('32da1e90-947b-5729-89ae-62d8294077e0', 'P02')</td>\n",
              "      <td>님잠만여 저 밖이엿어요 깨잇어?? 요즘 같습니다 ㅋㅋㅋㅋㅇ 일할때보다 뭔가 더 나돌...</td>\n",
              "      <td>0</td>\n",
              "      <td>[님잠만, 저, 밖, 엿, 어요, 깨, 잇어, ??, 요즘, 같습니다, ㅋㅋㅋㅇ, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             index  ...                                              sents\n",
              "0  ('d681fd70-af0d-5821-bd54-f411a26a2551', 'P01')  ...  [나, 할미, 생일, 파뤼파뤼, ~, 저녁, 먹고, 올게, 먹구, 옴, 나, 원, ...\n",
              "1  ('a9458b1e-2eb0-51b3-869e-665816baa439', 'P02')  ...  [근데, 서울, 요즘, 초, 그런거, 같기두, 하, 공, ㅠ, 부평, ?, 삼산동,...\n",
              "2  ('349322b2-f378-536e-a458-334b467bbb53', 'P02')  ...  [그니까, ㅋㅋㅋ, 맘, 먹었어, 지금, ㅋㅋㅋ, 담, 집들이, 때, 해서, 같이,...\n",
              "3  ('6721f5f0-5b9e-5e76-b5a8-dca6271695b0', 'P04')  ...                                          [내는, 지하철]\n",
              "4  ('b1300897-af6a-5a39-aa15-e7901c7137c9', 'P03')  ...                                           [강화도, ?]\n",
              "5  ('d869613c-5add-5b2b-8df4-7c33233ed6ee', 'P01')  ...  [여행, 하면서, 많이, 만나네, 어떤, 사람, 라오스, 남친, 만났대, 라오스, ...\n",
              "6  ('7ad5adee-b626-5d94-8a47-11e18b9fdb4d', 'P02')  ...  [둘다, 똑같은데, 공항, 혹시, 늦거나, 기다려야되, 거나, 시간, 촉박할까, 바...\n",
              "7  ('00b2ad12-cf69-5755-bdca-0f453b4f175d', 'P01')  ...  [어이없어, 아니야, ~, 그냥, 돌아가는것도, 싫고, 해서, 탔어, 도착, 지도,...\n",
              "8  ('74034247-a526-50d4-8494-c01e557c72cc', 'P02')  ...  [저녁, 갈거야, 너, ?, 집, 간다, 너, ?, 시, 응, 어디, 아프니, ?,...\n",
              "9  ('32da1e90-947b-5729-89ae-62d8294077e0', 'P02')  ...  [님잠만, 저, 밖, 엿, 어요, 깨, 잇어, ??, 요즘, 같습니다, ㅋㅋㅋㅇ, ...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suvwvKduemCP"
      },
      "source": [
        "# 전처리한 데이터프레임 저장\n",
        "output_file = '/content/gdrive/MyDrive/cose461/result_data_20.csv'\n",
        "df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcYfjWDICRit"
      },
      "source": [
        "데이터 전처리 고려해야 할 점 ㅜㅜ\n",
        "\n",
        "- ㅋㅋㅋㅋ, ㅇㅇㅇㅇ 어떻게 처리할지. 단순히 여러개 있어도 다 같은 걸로 취급할지 말지\n",
        "- !, ? 도 마찬가지. soynlp의 textonly 함수를 통해 기호들은 제거가 쉽게 가능할듯 한데. 그럼 정보의 손실이 있을수도\n",
        "- 이모티콘 이름. 우리 데이터에서 사람 이름은 #@이름# 으로 되어있음. \n",
        "- 형태소 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMXZcF68jtE7"
      },
      "source": [
        "### train, test data 만들기 및 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYJ0Mf4pU7Jt"
      },
      "source": [
        "# 전처리한 데이터 read_csv로 가져오기\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/cose461/my_result_data_20.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RsXO5MKKTWH"
      },
      "source": [
        "X = df['sents']\n",
        "y = df['P_gender']\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=7)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3VpFun6P2SY"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgdGogzYPtHD",
        "outputId": "4f4d4e3c-b038-4720-d063-cd3b96e89c16"
      },
      "source": [
        "print(len(tokenizer.word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEoQZw53QUzi",
        "outputId": "33ca4d2e-18f8-4316-dc56-90fcac3c76ec"
      },
      "source": [
        "threshold = 2\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)     # data 적게 할 때는 division by zero 나올수도\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 226216\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 134915\n",
            "단어 집합에서 희귀 단어의 비율: 59.639901686883334\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.1620115188483213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49HpD6EbQZzn",
        "outputId": "353a47d7-929d-425e-fed2-349612b0a12a"
      },
      "source": [
        "# 전체 단어 개수 중 빈도수 threshold 이하인 단어는 제거.\n",
        "# 0번 패딩 토큰을 고려하여 + 1\n",
        "vocab_size = total_cnt - rare_cnt + 1\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 91302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGp5qrHyQde1"
      },
      "source": [
        "#tokenizer = Tokenizer(vocab_size,  filters='[\\\\].,\\t\\n')#filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n') \n",
        "tokenizer = Tokenizer(vocab_size,  filters='[\\\\].,\\'\\\"\\t\\n')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xkPrH5BsIAc"
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icyx5G7Tj5qL"
      },
      "source": [
        "### 빈 데이터 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e4eBD-Dj8bZ"
      },
      "source": [
        "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMUevdI9j8Oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae94756-7f55-4598-91c8-612c80d88c21"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "X_train = np.delete(X_train, drop_train, axis=0)\n",
        "y_train = np.delete(y_train, drop_train, axis=0)\n",
        "\n",
        "print(\"----After drop empty samples----\")\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158996\n",
            "158996\n",
            "----After drop empty samples----\n",
            "158930\n",
            "158930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhuac0kDkHMO"
      },
      "source": [
        "### 패딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "R_Yq-mq8R0Jf",
        "outputId": "24d68e16-a693-43ee-f047-8f0704a82d8e"
      },
      "source": [
        "print('메시지의 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('메시지의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "메시지의 최대 길이 : 503\n",
            "메시지의 평균 길이 : 23.240980305795006\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjNMmaB2SQza",
        "outputId": "ac982a82-2b23-4548-ad95-fb1738b135b1"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))\n",
        "\n",
        "below_threshold_len(80,X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 80 이하인 샘플의 비율: 99.40854464229535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T0ovxUDSdfd"
      },
      "source": [
        "max_len = 80\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lzkwGnNkK4N"
      },
      "source": [
        "### 모델 정의 및 train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR0DkfIzSjEv"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Conv1D, MaxPooling1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j_sc6ZnLnzI"
      },
      "source": [
        "# best_model 저장해줄 위치. 매번 다르게 해야 됨.\n",
        "best_model = 'best_model_1117_13.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj1hOhFBLzpt"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint(best_model, monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8LfO6y2Lv0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0224d3-c1bb-4fb4-f718-0229d3e5fc44"
      },
      "source": [
        "# two layer LSTM\n",
        "\n",
        "embedding_dim2 = 200\n",
        "hidden_units1 = 128\n",
        "hidden_units2 = 256\n",
        "hidden_units3 = 128\n",
        "hidden_units4 = 128\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(vocab_size, embedding_dim2))\n",
        "model2.add(LSTM(hidden_units1,activation='relu',return_sequences = True))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(1024, activation='relu'))\n",
        "model2.add(LSTM(hidden_units2,activation='relu',return_sequences = True))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(1024, activation='relu'))\n",
        "model2.add(LSTM(hidden_units3,activation='relu',return_sequences=True))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(LSTM(hidden_units4,activation='relu',return_sequences=False))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(1024, activation='relu'))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEDC5w68bhQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c136e4-f63c-4135-c4f7-fd0d435d5a5d"
      },
      "source": [
        "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model2.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1987/1987 [==============================] - ETA: 0s - loss: 4303.6758 - acc: 0.5732\n",
            "Epoch 00001: val_acc improved from -inf to 0.53615, saving model to best_model_1117_13.h5\n",
            "1987/1987 [==============================] - 2136s 1s/step - loss: 4303.6758 - acc: 0.5732 - val_loss: 3459.0439 - val_acc: 0.5361\n",
            "Epoch 2/15\n",
            " 461/1987 [=====>........................] - ETA: 26:33 - loss: 13.5894 - acc: 0.6582"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_tvKsG4S1nN",
        "outputId": "5009bbc4-db2f-47f2-c31c-961c58be047b"
      },
      "source": [
        "# test error\n",
        "loaded_model = load_model(best_model)\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1243/1243 [==============================] - 30s 23ms/step - loss: 0.5872 - acc: 0.6835\n",
            "\n",
            " 테스트 정확도: 0.6835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1TM4HqRKM3S",
        "outputId": "e8556d7a-e6ee-4fba-e406-610608f93a69"
      },
      "source": [
        "# train error\n",
        "loaded_model = load_model(best_model)\n",
        "print(\"\\n train 정확도: %.4f\" % (loaded_model.evaluate(X_train, y_train)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4967/4967 [==============================] - 113s 22ms/step - loss: 0.5253 - acc: 0.7484\n",
            "\n",
            " train 정확도: 0.7484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ee0l2QUTPnN",
        "outputId": "681dfbf1-6c37-4683-a499-0b0e53f6d1f4"
      },
      "source": [
        "model2.predict([[4]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.53094757]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    }
  ]
}